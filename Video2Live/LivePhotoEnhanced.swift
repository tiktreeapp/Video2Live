import Foundation
import AVFoundation
import Photos
import UIKit

class LivePhotoEnhanced {
    // å•ä¾‹æ¨¡å¼
    static let shared = LivePhotoEnhanced()
    private init() {}
    
    // æ—¥å¿—å·¥å…·
    private func log(_ message: String) {
        print("ğŸ“ [LivePhotoEnhanced] \(message)")
    }
    
    // åªä¿ç•™AVFoundationå¤„ç†æ–¹æ³•
    func processVideoWithAVFoundation(
        inputURL: URL,
        outputURL: URL,
        startTime: Double,
        duration: Double
    ) async throws {
        // åˆ›å»ºAVAsset
        let asset = AVAsset(url: inputURL)
        
        // åˆ›å»ºæ—¶é—´èŒƒå›´
        let timeRange = CMTimeRange(
            start: CMTime(seconds: startTime, preferredTimescale: 600),
            duration: CMTime(seconds: duration, preferredTimescale: 600)
        )
        
        // ä½¿ç”¨AVFoundationå¯¼å‡º
        let composition = AVMutableComposition()
        
        // æ·»åŠ è§†é¢‘è½¨é“
        if let videoTrack = composition.addMutableTrack(
            withMediaType: .video,
            preferredTrackID: kCMPersistentTrackID_Invalid
        ), let assetVideoTrack = try? await asset.loadTracks(withMediaType: .video).first {
            let preferredTransform = try? await assetVideoTrack.load(.preferredTransform)
            videoTrack.preferredTransform = preferredTransform ?? .identity
            try? videoTrack.insertTimeRange(timeRange, of: assetVideoTrack, at: .zero)
        }
        
        // æ·»åŠ éŸ³é¢‘è½¨é“
        if let audioTrack = try? await asset.loadTracks(withMediaType: .audio).first,
           let compositionAudioTrack = composition.addMutableTrack(
               withMediaType: .audio,
               preferredTrackID: kCMPersistentTrackID_Invalid
           ) {
            try? compositionAudioTrack.insertTimeRange(timeRange, of: audioTrack, at: .zero)
        }
        
        // å¯¼å‡º
        if let exporter = AVAssetExportSession(
            asset: composition,
            presetName: AVAssetExportPresetHighestQuality
        ) {
            exporter.outputURL = outputURL
            exporter.outputFileType = .mov
            await exporter.export()
            
            if exporter.status == .completed {
                log("âœ… è§†é¢‘å¤„ç†æˆåŠŸ")
            } else {
                throw NSError(domain: "ExportError", code: -1,
                             userInfo: [NSLocalizedDescriptionKey: "è§†é¢‘å¯¼å‡ºå¤±è´¥"])
            }
        }
    }
    
    // ä¿ç•™å›¾ç‰‡å¤„ç†æ–¹æ³•
    func extractAndProcessImage(
        from asset: AVAsset,
        at time: CMTime,
        outputURL: URL,
        livePhotoID: String
    ) async throws {
        // ä½¿ç”¨AVFoundationæå–å…³é”®å¸§
        let imageGenerator = AVAssetImageGenerator(asset: asset)
        imageGenerator.appliesPreferredTrackTransform = true
        imageGenerator.requestedTimeToleranceBefore = .zero
        imageGenerator.requestedTimeToleranceAfter = .zero
        
        let cgImage = try await imageGenerator.image(at: time).image
        let image = UIImage(cgImage: cgImage)
        
        // åˆ›å»ºä¸€ä¸ªå¸¦æœ‰é¢å¤–å…ƒæ•°æ®çš„å›¾ç‰‡
        guard let source = CGImageSourceCreateWithData(image.jpegData(compressionQuality: 1.0)! as CFData, nil) else {
            throw NSError(domain: "ImageError", code: -1, userInfo: nil)
        }
        
        let metadata = NSMutableDictionary()
        metadata["com.apple.quicktime.live-photo"] = "1"
        metadata["com.apple.quicktime.content.identifier"] = livePhotoID
        
        let destination = CGImageDestinationCreateWithURL(outputURL as CFURL, UTType.jpeg.identifier as CFString, 1, nil)!
        CGImageDestinationAddImageFromSource(destination, source, 0, metadata)
        CGImageDestinationFinalize(destination)
        
        log("âœ… å›¾ç‰‡å¤„ç†æˆåŠŸ")
    }
} 
