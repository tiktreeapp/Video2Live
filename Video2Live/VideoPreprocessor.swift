import Foundation
import AVFoundation
import Photos
import UIKit

/// è§†é¢‘é¢„å¤„ç†å™¨ - ä¸“ä¸ºLive Photoè½¬æ¢ä¼˜åŒ–
class VideoPreprocessor {
    
    // æ—¥å¿—è®°å½•
    private func log(_ message: String) {
        print("ğŸ¬ [VideoPreprocessor] \(message)")
    }
    
    /// é¢„å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œç¡®ä¿ç¬¦åˆLive Photoè¦æ±‚
    func preprocessVideoForLivePhoto(
        inputURL: URL,
        quality: ConversionQuality = .balanced,
        completion: @escaping (Result<URL, Error>) -> Void
    ) {
        Task {
            do {
                log("å¼€å§‹é¢„å¤„ç†è§†é¢‘: \(inputURL.path), è´¨é‡è®¾ç½®: \(quality)")
                
                // 1. éªŒè¯è¾“å…¥æ–‡ä»¶
                try await validateInputFile(inputURL)
                
                // 2. åˆ†æè§†é¢‘å±æ€§
                let videoInfo = try await analyzeVideo(inputURL)
                log("è§†é¢‘åˆ†æå®Œæˆ: \(videoInfo)")
                
                // 3. æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬ç 
                if needsTranscoding(videoInfo) {
                    log("è§†é¢‘éœ€è¦è½¬ç å¤„ç†")
                    let processedURL = try await transcodeVideo(inputURL, videoInfo: videoInfo, quality: quality)
                    log("è§†é¢‘è½¬ç å®Œæˆ: \(processedURL.path)")
                    completion(.success(processedURL))
                } else {
                    log("è§†é¢‘æ ¼å¼ç¬¦åˆè¦æ±‚ï¼Œæ— éœ€è½¬ç ")
                    // æ ¹æ®è´¨é‡è®¾ç½®ï¼Œå¯èƒ½ä»éœ€è¦ä¼˜åŒ–
                    if quality == .high {
                        log("é«˜è´¨é‡æ¨¡å¼ï¼šå³ä½¿æ ¼å¼ç¬¦åˆä¹Ÿè¿›è¡Œä¼˜åŒ–")
                        let processedURL = try await transcodeVideo(inputURL, videoInfo: videoInfo, quality: quality)
                        completion(.success(processedURL))
                    } else {
                        completion(.success(inputURL))
                    }
                }
                
            } catch {
                log("âŒ é¢„å¤„ç†å¤±è´¥: \(error)")
                completion(.failure(error))
            }
        }
    }
    
    /// éªŒè¯è¾“å…¥æ–‡ä»¶
    private func validateInputFile(_ url: URL) async throws {
        log("éªŒè¯è¾“å…¥æ–‡ä»¶...")
        
        guard FileManager.default.fileExists(atPath: url.path) else {
            throw PreprocessingError.fileNotFound
        }
        
        let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
        guard let fileSize = attributes[.size] as? Int64 else {
            throw PreprocessingError.invalidFileAttributes
        }
        
        let sizeInMB = Double(fileSize) / 1024.0 / 1024.0
        log("æ–‡ä»¶å¤§å°: \(String(format: "%.2f", sizeInMB)) MB")
        
        if sizeInMB < 0.1 {
            throw PreprocessingError.fileTooSmall
        }
        
        if sizeInMB > 500 {
            log("âš ï¸ æ–‡ä»¶è¾ƒå¤§ï¼Œå¤„ç†å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´")
        }
        
        // æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        let allowedExtensions = ["mp4", "mov", "m4v", "3gp", "avi", "mkv"]
        let fileExtension = url.pathExtension.lowercased()
        
        if !allowedExtensions.contains(fileExtension) {
            log("âš ï¸ æ–‡ä»¶æ‰©å±•åå¯èƒ½ä¸æ”¯æŒ: \(fileExtension)")
        }
    }
    
    /// åˆ†æè§†é¢‘å±æ€§
    private func analyzeVideo(_ url: URL) async throws -> VideoInfo {
        log("åˆ†æè§†é¢‘å±æ€§...")
        
        let asset = AVAsset(url: url)
        
        // è·å–åŸºæœ¬ä¿¡æ¯
        let duration = try await asset.load(.duration)
        let durationInSeconds = duration.seconds
        
        log("è§†é¢‘æ—¶é•¿: \(String(format: "%.2f", durationInSeconds)) ç§’")
        
        if durationInSeconds < 1.0 {
            throw PreprocessingError.videoTooShort
        }
        
        if durationInSeconds > 10.0 {
            log("âš ï¸ è§†é¢‘è¾ƒé•¿ï¼Œå°†æˆªå–å‰10ç§’")
        }
        
        // è·å–è§†é¢‘è½¨é“ä¿¡æ¯
        let videoTracks = try await asset.loadTracks(withMediaType: .video)
        guard let videoTrack = videoTracks.first else {
            throw PreprocessingError.noVideoTrack
        }
        
        // è·å–è§†é¢‘å±æ€§
        let naturalSize = try await videoTrack.load(.naturalSize)
        let preferredTransform = try await videoTrack.load(.preferredTransform)
        
        log("è§†é¢‘å°ºå¯¸: \(naturalSize)")
        log("é¦–é€‰å˜æ¢: \(preferredTransform)")
        
        // æ£€æŸ¥æ ¼å¼æè¿°
        let formatDescriptions = try await videoTrack.load(.formatDescriptions)
        log("æ ¼å¼æè¿°æ•°é‡: \(formatDescriptions.count)")
        
        // è·å–å¸§ç‡
        let nominalFrameRate = videoTrack.nominalFrameRate
        log("å¸§ç‡: \(nominalFrameRate) fps")
        
        // è·å–éŸ³é¢‘è½¨é“ä¿¡æ¯
        let audioTracks = try await asset.loadTracks(withMediaType: .audio)
        log("éŸ³é¢‘è½¨é“æ•°é‡: \(audioTracks.count)")
        
        return VideoInfo(
            duration: durationInSeconds,
            naturalSize: naturalSize,
            frameRate: nominalFrameRate,
            hasAudio: !audioTracks.isEmpty,
            formatDescriptions: formatDescriptions
        )
    }
    
    /// æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬ç 
    private func needsTranscoding(_ info: VideoInfo) -> Bool {
        log("æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬ç ...")
        
        // æ£€æŸ¥å¸§ç‡ï¼ˆLive Photoæ¨è30fpsï¼‰
        if info.frameRate > 0 && (info.frameRate < 24 || info.frameRate > 60) {
            log("å¸§ç‡(\(info.frameRate))ä¸åœ¨æ¨èèŒƒå›´(24-60fps)")
            return true
        }
        
        // æ£€æŸ¥åˆ†è¾¨ç‡ï¼ˆæ¨è1080pæˆ–æ›´ä½ï¼‰
        let maxDimension = max(info.naturalSize.width, info.naturalSize.height)
        if maxDimension > 1920 {
            log("åˆ†è¾¨ç‡è¿‡é«˜ï¼Œå»ºè®®é™ä½")
            return true
        }
        
        // æ£€æŸ¥æ—¶é•¿ï¼ˆLive Photoé€šå¸¸1-3ç§’ï¼‰
        if info.duration > 5.0 {
            log("è§†é¢‘æ—¶é•¿è¶…è¿‡5ç§’ï¼Œéœ€è¦æˆªå–")
            return true
        }
        
        // æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘ï¼ˆå¯é€‰ï¼Œä½†æœ‰éŸ³é¢‘çš„Live Photoä½“éªŒæ›´å¥½ï¼‰
        if !info.hasAudio {
            log("è§†é¢‘æ²¡æœ‰éŸ³é¢‘è½¨é“")
        }
        
        return false
    }
    
    /// è½¬ç è§†é¢‘ï¼ˆæ”¯æŒè´¨é‡è®¾ç½®ï¼‰
    private func transcodeVideo(_ inputURL: URL, videoInfo: VideoInfo, quality: ConversionQuality) async throws -> URL {
        log("å¼€å§‹è½¬ç è§†é¢‘...")
        
        let tempDir = FileManager.default.temporaryDirectory
        let outputURL = tempDir.appendingPathComponent("processed_\(UUID().uuidString).mov")
        
        let asset = AVAsset(url: inputURL)
        
        // åˆ›å»ºåˆæˆ
        let composition = AVMutableComposition()
        
        // æ·»åŠ è§†é¢‘è½¨é“
        guard let videoTrack = composition.addMutableTrack(
            withMediaType: .video,
            preferredTrackID: kCMPersistentTrackID_Invalid
        ) else {
            throw PreprocessingError.exportSessionCreationFailed
        }
        
        // è·å–åŸå§‹è§†é¢‘è½¨é“
        let assetVideoTracks = try await asset.loadTracks(withMediaType: .video)
        guard let assetVideoTrack = assetVideoTracks.first else {
            throw PreprocessingError.noVideoTrack
        }
        
        // ä¿å­˜åŸå§‹å˜æ¢
        let preferredTransform = try await assetVideoTrack.load(.preferredTransform)
        videoTrack.preferredTransform = preferredTransform
        
        // æ ¹æ®è´¨é‡è®¾ç½®è°ƒæ•´æ—¶é—´èŒƒå›´
        let maxDuration = min(videoInfo.duration, quality.maxDuration)
        let optimalTimeRange = await findOptimalTimeRange(for: videoInfo, in: asset, maxDuration: maxDuration)
        log("é€‰æ‹©çš„è§†é¢‘ç‰‡æ®µ: \(optimalTimeRange.start.seconds)-\(optimalTimeRange.end.seconds) ç§’ (è´¨é‡: \(quality.rawValue))")
        
        try videoTrack.insertTimeRange(optimalTimeRange, of: assetVideoTrack, at: .zero)
        
        // æ·»åŠ éŸ³é¢‘è½¨é“ï¼ˆå¦‚æœæœ‰ï¼‰
        let audioTracks = try await asset.loadTracks(withMediaType: .audio)
        if !audioTracks.isEmpty,
           let audioTrack = audioTracks.first,
           let compositionAudioTrack = composition.addMutableTrack(
                withMediaType: .audio,
                preferredTrackID: kCMPersistentTrackID_Invalid
           ) {
            try compositionAudioTrack.insertTimeRange(optimalTimeRange, of: audioTrack, at: .zero)
            log("å·²æ·»åŠ éŸ³é¢‘è½¨é“")
        }
        
        // æ ¹æ®è´¨é‡è®¾ç½®é€‰æ‹©å¯¼å‡ºé¢„è®¾
        let presetName = quality.presetName
        log("ä½¿ç”¨å¯¼å‡ºé¢„è®¾: \(presetName) (è´¨é‡: \(quality.rawValue))")
        
        // åˆ›å»ºå¯¼å‡ºä¼šè¯
        guard let exportSession = AVAssetExportSession(
            asset: composition,
            presetName: presetName
        ) else {
            throw PreprocessingError.exportSessionCreationFailed
        }
        
        // é…ç½®å¯¼å‡ºå‚æ•°
        exportSession.outputURL = outputURL
        exportSession.outputFileType = .mov
        exportSession.shouldOptimizeForNetworkUse = true
        exportSession.timeRange = optimalTimeRange
        
        // æ·»åŠ Live Photoå…ƒæ•°æ®
        let uuid = UUID().uuidString
        let metadata = [
            createMetadataItem(key: "com.apple.quicktime.live-photo", value: "1"),
            createMetadataItem(key: "com.apple.quicktime.content.identifier", value: uuid),
            createMetadataItem(key: "com.apple.quicktime.still-image-time", value: "0")
        ]
        exportSession.metadata = metadata
        
        // å¯¼å‡ºè§†é¢‘
        log("å¯¼å‡ºè§†é¢‘...")
        await exportSession.export()
        
        guard exportSession.status == .completed else {
            let error = exportSession.error ?? PreprocessingError.exportFailed
            log("âŒ å¯¼å‡ºå¤±è´¥: \(error)")
            throw error
        }
        
        // éªŒè¯è¾“å‡ºæ–‡ä»¶
        try await validateOutputFile(outputURL)
        
        log("âœ… è½¬ç å®Œæˆ")
        return outputURL
    }
    
    /// æ™ºèƒ½é€‰æ‹©æœ€ä½³æ—¶é—´èŒƒå›´
    private func findOptimalTimeRange(for videoInfo: VideoInfo, in asset: AVAsset, maxDuration: Double) async -> CMTimeRange {
        // å¦‚æœè§†é¢‘å¾ˆçŸ­ï¼Œä½¿ç”¨æ•´ä¸ªè§†é¢‘
        if videoInfo.duration <= maxDuration {
            return CMTimeRange(
                start: .zero,
                duration: CMTime(seconds: videoInfo.duration, preferredTimescale: 600)
            )
        }
        
        // å°è¯•æ‰¾åˆ°æœ€ç¨³å®šçš„ç‰‡æ®µï¼ˆè¿åŠ¨è¾ƒå°‘çš„éƒ¨åˆ†ï¼‰
        do {
            let optimalStartTime = try await findMostStableSegment(in: asset, maxDuration: maxDuration)
            log("æ‰¾åˆ°æœ€ç¨³å®šç‰‡æ®µå¼€å§‹æ—¶é—´: \(optimalStartTime.seconds) ç§’")
            
            return CMTimeRange(
                start: CMTime(seconds: optimalStartTime.seconds, preferredTimescale: 600),
                duration: CMTime(seconds: maxDuration, preferredTimescale: 600)
            )
        } catch {
            log("âš ï¸ æ— æ³•æ‰¾åˆ°æœ€ä¼˜ç‰‡æ®µï¼Œä½¿ç”¨é»˜è®¤å¼€å§‹æ—¶é—´: \(error)")
            // å›é€€åˆ°ä½¿ç”¨è§†é¢‘å¼€å§‹éƒ¨åˆ†
            return CMTimeRange(
                start: .zero,
                duration: CMTime(seconds: maxDuration, preferredTimescale: 600)
            )
        }
    }
    
    /// æ‰¾åˆ°æœ€ç¨³å®šçš„è§†é¢‘ç‰‡æ®µ
    private func findMostStableSegment(in asset: AVAsset, maxDuration: Double) async throws -> CMTime {
        // ç®€åŒ–å®ç°ï¼šåˆ†æè§†é¢‘çš„è¿åŠ¨æƒ…å†µ
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç®—æ³•
        
        let totalDuration = try await asset.load(.duration).seconds
        let analysisInterval = 0.5 // æ¯0.5ç§’åˆ†æä¸€æ¬¡
        
        var minMotionScore = Double.greatestFiniteMagnitude
        var bestStartTime = 0.0
        
        // åˆ†æå‰10ç§’ï¼Œæ‰¾åˆ°è¿åŠ¨æœ€å°‘çš„ç‰‡æ®µ
        let analysisDuration = min(totalDuration, 10.0)
        
        var currentTime = 0.0
        while currentTime + maxDuration <= analysisDuration {
            let motionScore = try await analyzeMotion(in: asset, at: currentTime, duration: maxDuration)
            
            if motionScore < minMotionScore {
                minMotionScore = motionScore
                bestStartTime = currentTime
            }
            
            currentTime += analysisInterval
        }
        
        return CMTime(seconds: bestStartTime, preferredTimescale: 600)
    }
    
    /// åˆ†ææŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„è¿åŠ¨æƒ…å†µ
    private func analyzeMotion(in asset: AVAsset, at startTime: Double, duration: Double) async throws -> Double {
        // æå–å¤šä¸ªå…³é”®å¸§è¿›è¡Œè¿åŠ¨åˆ†æ
        let imageGenerator = AVAssetImageGenerator(asset: asset)
        imageGenerator.appliesPreferredTrackTransform = true
        
        let frameCount = 5 // åˆ†æ5ä¸ªå…³é”®å¸§
        let timeStep = duration / Double(frameCount - 1)
        var frames: [CGImage] = []
        
        for i in 0..<frameCount {
            let time = startTime + Double(i) * timeStep
            let cgImage = try await imageGenerator.image(at: CMTime(seconds: time, preferredTimescale: 600)).image
            frames.append(cgImage)
        }
        
        // è®¡ç®—ç›¸é‚»å¸§ä¹‹é—´çš„å¹³å‡å·®å¼‚
        var totalMotionScore = 0.0
        for i in 0..<(frames.count - 1) {
            let motionScore = calculateImageDifference(frames[i], frames[i + 1])
            totalMotionScore += motionScore
        }
        
        let averageMotionScore = totalMotionScore / Double(frames.count - 1)
        log("ç‰‡æ®µ \(startTime)-\(startTime + duration) è¿åŠ¨è¯„åˆ†: \(String(format: "%.3f", averageMotionScore))")
        
        return averageMotionScore
    }
    
    /// è®¡ç®—ä¸¤å¼ å›¾ç‰‡çš„å·®å¼‚åº¦ï¼ˆæ”¹è¿›ç‰ˆï¼‰
    private func calculateImageDifference(_ image1: CGImage, _ image2: CGImage) -> Double {
        // æ£€æŸ¥åŸºæœ¬å±æ€§
        let size1 = CGSize(width: image1.width, height: image1.height)
        let size2 = CGSize(width: image2.width, height: image2.height)
        
        if size1 != size2 {
            return 1.0 // å°ºå¯¸ä¸åŒï¼Œå·®å¼‚åº¦æœ€å¤§
        }
        
        // ç®€åŒ–çš„åƒç´ çº§å·®å¼‚è®¡ç®—
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç®—æ³•å¦‚SSIMã€PSNRç­‰
        guard let data1 = image1.dataProvider?.data,
              let data2 = image2.dataProvider?.data else {
            return 0.5 // æ— æ³•è·å–æ•°æ®ï¼Œè¿”å›ä¸­ç­‰å·®å¼‚åº¦
        }
        
        let length1 = CFDataGetLength(data1)
        let length2 = CFDataGetLength(data2)
        
        if length1 != length2 {
            return 0.8 // æ•°æ®é•¿åº¦ä¸åŒï¼Œå·®å¼‚åº¦è¾ƒé«˜
        }
        
        let bytes1 = CFDataGetBytePtr(data1)
        let bytes2 = CFDataGetBytePtr(data2)
        
        var totalDifference: Double = 0
        let sampleSize = min(length1, 10000) // é‡‡æ ·æ¯”è¾ƒï¼Œæé«˜æ€§èƒ½
        let step = max(1, length1 / sampleSize)
        
        for i in stride(from: 0, to: length1, by: step) {
            let diff = abs(Int(bytes1[i]) - Int(bytes2[i]))
            totalDifference += Double(diff)
        }
        
        let averageDifference = totalDifference / Double(sampleSize)
        let normalizedDifference = min(averageDifference / 255.0, 1.0) // å½’ä¸€åŒ–åˆ°0-1èŒƒå›´
        
        return normalizedDifference
    }
    
    /// æå–æœ€ä½³å…³é”®å¸§
    func extractOptimalKeyFrame(from asset: AVAsset, in timeRange: CMTimeRange) async throws -> UIImage {
        log("æå–æœ€ä½³å…³é”®å¸§...")
        
        let imageGenerator = AVAssetImageGenerator(asset: asset)
        imageGenerator.appliesPreferredTrackTransform = true
        imageGenerator.requestedTimeToleranceBefore = .zero
        imageGenerator.requestedTimeToleranceAfter = .zero
        
        // åœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…æå–å¤šä¸ªå€™é€‰å¸§
        let candidateCount = 5
        let timeStep = timeRange.duration.seconds / Double(candidateCount - 1)
        var candidates: [(image: UIImage, score: Double, time: Double)] = []
        
        for i in 0..<candidateCount {
            let time = timeRange.start.seconds + Double(i) * timeStep
            let cgImage = try await imageGenerator.image(at: CMTime(seconds: time, preferredTimescale: 600)).image
            let image = UIImage(cgImage: cgImage)
            
            // è¯„ä¼°å¸§è´¨é‡
            let qualityScore = evaluateFrameQuality(image, at: time, in: timeRange)
            candidates.append((image: image, score: qualityScore, time: time))
            
            log("å€™é€‰å¸§ \(i + 1): æ—¶é—´\(String(format: "%.2f", time))s, è´¨é‡è¯„åˆ†\(String(format: "%.3f", qualityScore))")
        }
        
        // é€‰æ‹©è¯„åˆ†æœ€é«˜çš„å¸§
        guard let bestCandidate = candidates.max(by: { $0.score < $1.score }) else {
            throw PreprocessingError.imageProcessingFailed
        }
        
        log("âœ… é€‰æ‹©æœ€ä½³å…³é”®å¸§: æ—¶é—´\(String(format: "%.2f", bestCandidate.time))s, è¯„åˆ†\(String(format: "%.3f", bestCandidate.score))")
        return bestCandidate.image
    }
    
    /// è¯„ä¼°å¸§è´¨é‡
    private func evaluateFrameQuality(_ image: UIImage, at time: Double, in timeRange: CMTimeRange) -> Double {
        var score = 1.0
        
        // 1. åå¥½æ—¶é—´èŒƒå›´å†…çš„ä¸­é—´ä½ç½®
        let timeScore = 1.0 - abs(time - (timeRange.start.seconds + timeRange.duration.seconds / 2)) / (timeRange.duration.seconds / 2)
        score += timeScore * 0.3
        
        // 2. æ£€æŸ¥å›¾åƒæ¸…æ™°åº¦ï¼ˆé€šè¿‡ç®€å•çš„è¾¹ç¼˜æ£€æµ‹ï¼‰
        let sharpnessScore = estimateImageSharpness(image)
        score += sharpnessScore * 0.4
        
        // 3. æ£€æŸ¥äº®åº¦ï¼ˆé¿å…è¿‡æš—æˆ–è¿‡äº®çš„å›¾åƒï¼‰
        let brightnessScore = evaluateBrightness(image)
        score += brightnessScore * 0.3
        
        return score
    }
    
    /// ä¼°è®¡å›¾åƒæ¸…æ™°åº¦
    private func estimateImageSharpness(_ image: UIImage) -> Double {
        // ç®€åŒ–çš„æ¸…æ™°åº¦è¯„ä¼°
        // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯ä»¥ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­æˆ–æ¢¯åº¦è®¡ç®—
        
        guard let cgImage = image.cgImage else { return 0.5 }
        
        let width = cgImage.width
        let height = cgImage.height
        
        // ç®€å•çš„è¾¹ç¼˜æ£€æµ‹ï¼ˆè®¡ç®—ç›¸é‚»åƒç´ çš„å·®å¼‚ï¼‰
        guard let dataProvider = cgImage.dataProvider,
              let data = dataProvider.data else {
            return 0.5
        }
        
        let bytes = CFDataGetBytePtr(data)
        let length = CFDataGetLength(data)
        
        var edgeSum = 0
        let sampleStride = max(1, length / 1000) // é‡‡æ ·ä»¥æé«˜æ€§èƒ½
        
        for i in stride(from: 4, to: length - 4, by: sampleStride * 4) { // å‡è®¾RGBAæ ¼å¼
            let pixelDiff = abs(Int(bytes[i]) - Int(bytes[i - 4]))
            edgeSum += pixelDiff
        }
        
        let averageEdge = Double(edgeSum) / Double(length / sampleStride)
        let normalizedSharpness = min(averageEdge / 50.0, 1.0) // å½’ä¸€åŒ–
        
        return normalizedSharpness
    }
    
    /// è¯„ä¼°å›¾åƒäº®åº¦
    private func evaluateBrightness(_ image: UIImage) -> Double {
        guard let cgImage = image.cgImage else { return 0.5 }
        
        let width = cgImage.width
        let height = cgImage.height
        let totalPixels = width * height
        
        guard let dataProvider = cgImage.dataProvider,
              let data = dataProvider.data else {
            return 0.5
        }
        
        let bytes = CFDataGetBytePtr(data)
        let length = CFDataGetLength(data)
        
        var totalBrightness = 0
        let sampleStride = max(1, length / 1000) // é‡‡æ ·ä»¥æé«˜æ€§èƒ½
        
        for i in stride(from: 0, to: length, by: sampleStride) {
            totalBrightness += Int(bytes[i])
        }
        
        let averageBrightness = Double(totalBrightness) / Double(length / sampleStride)
        let normalizedBrightness = averageBrightness / 255.0
        
        // åå¥½ä¸­ç­‰äº®åº¦ï¼ˆ0.3-0.7èŒƒå›´ï¼‰
        let optimalBrightness = 0.5
        let brightnessScore = 1.0 - abs(normalizedBrightness - optimalBrightness) * 2.0
        
        return max(0.0, brightnessScore)
    }
    
    // ç§»é™¤æ—§çš„ selectOptimalPreset æ–¹æ³•ï¼Œç°åœ¨ä½¿ç”¨ ConversionQuality çš„è®¾ç½®
    
    /// éªŒè¯è¾“å‡ºæ–‡ä»¶
    private func validateOutputFile(_ url: URL) async throws {
        log("éªŒè¯è¾“å‡ºæ–‡ä»¶...")
        
        guard FileManager.default.fileExists(atPath: url.path) else {
            throw PreprocessingError.exportFailed
        }
        
        let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
        guard let fileSize = attributes[.size] as? Int64 else {
            throw PreprocessingError.invalidFileAttributes
        }
        
        let sizeInMB = Double(fileSize) / 1024.0 / 1024.0
        log("è¾“å‡ºæ–‡ä»¶å¤§å°: \(String(format: "%.2f", sizeInMB)) MB")
        
        if sizeInMB < 0.1 {
            throw PreprocessingError.fileTooSmall
        }
        
        // éªŒè¯è§†é¢‘æ–‡ä»¶å®Œæ•´æ€§
        let asset = AVAsset(url: url)
        let duration = try await asset.load(.duration)
        
        if duration.seconds < 0.1 {
            throw PreprocessingError.videoTooShort
        }
        
        log("âœ… è¾“å‡ºæ–‡ä»¶éªŒè¯é€šè¿‡")
    }
    
    /// åˆ›å»ºå…ƒæ•°æ®é¡¹
    private func createMetadataItem(key: String, value: String) -> AVMetadataItem {
        let item = AVMutableMetadataItem()
        item.key = key as NSString
        item.keySpace = AVMetadataKeySpace.quickTimeMetadata
        item.value = value as NSString
        return item
    }
    
    /// è·å–æ¨èçš„Live Photoè®¾ç½®
    static func getRecommendedSettings() -> [String: Any] {
        return [
            "duration": "1-3 seconds",
            "resolution": "1080p or lower",
            "frameRate": "24-30 fps",
            "format": "H.264 video with AAC audio",
            "fileSize": "< 100MB"
        ]
    }
    
    /// å¿«é€Ÿæ£€æŸ¥è§†é¢‘æ˜¯å¦é€‚åˆLive Photoè½¬æ¢
    func quickCheckVideoCompatibility(_ url: URL) async -> (isCompatible: Bool, issues: [String]) {
        var issues: [String] = []
        
        do {
            // åŸºæœ¬æ–‡ä»¶æ£€æŸ¥
            guard FileManager.default.fileExists(atPath: url.path) else {
                issues.append("æ–‡ä»¶ä¸å­˜åœ¨")
                return (false, issues)
            }
            
            let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
            if let fileSize = attributes[.size] as? Int64 {
                let sizeInMB = Double(fileSize) / 1024.0 / 1024.0
                if sizeInMB < 0.1 {
                    issues.append("æ–‡ä»¶å¤ªå°")
                } else if sizeInMB > 500 {
                    issues.append("æ–‡ä»¶è¿‡å¤§ï¼Œå¤„ç†æ—¶é—´å¯èƒ½è¾ƒé•¿")
                }
            }
            
            // è§†é¢‘å±æ€§æ£€æŸ¥
            let asset = AVAsset(url: url)
            let duration = try await asset.load(.duration)
            let durationInSeconds = duration.seconds
            
            if durationInSeconds < 1.0 {
                issues.append("è§†é¢‘æ—¶é•¿å¤ªçŸ­")
            } else if durationInSeconds > 10.0 {
                issues.append("è§†é¢‘æ—¶é•¿è¿‡é•¿ï¼Œå°†æˆªå–å‰10ç§’")
            }
            
            let videoTracks = try await asset.loadTracks(withMediaType: .video)
            if videoTracks.isEmpty {
                issues.append("æ²¡æœ‰è§†é¢‘è½¨é“")
            } else if let videoTrack = videoTracks.first {
                let naturalSize = try await videoTrack.load(.naturalSize)
                let maxDimension = max(naturalSize.width, naturalSize.height)
                
                if maxDimension > 1920 {
                    issues.append("åˆ†è¾¨ç‡è¿‡é«˜ï¼Œå°†è‡ªåŠ¨é™ä½")
                }
                
                let frameRate = videoTrack.nominalFrameRate
                if frameRate > 0 && (frameRate < 24 || frameRate > 60) {
                    issues.append("å¸§ç‡ä¸åœ¨æ¨èèŒƒå›´(24-60fps)")
                }
            }
            
            return (issues.isEmpty, issues)
            
        } catch {
            issues.append("æ— æ³•åˆ†æè§†é¢‘: \(error.localizedDescription)")
            return (false, issues)
        }
    }
    
    /// è·å–è§†é¢‘é¢„è§ˆä¿¡æ¯
    func getVideoPreviewInfo(_ url: URL) async -> VideoPreviewInfo? {
        do {
            let asset = AVAsset(url: url)
            let duration = try await asset.load(.duration)
            let videoTracks = try await asset.loadTracks(withMediaType: .video)
            
            guard let videoTrack = videoTracks.first else {
                return nil
            }
            
            let naturalSize = try await videoTrack.load(.naturalSize)
            let frameRate = videoTrack.nominalFrameRate
            let hasAudio = !(try await asset.loadTracks(withMediaType: .audio)).isEmpty
            
            // æå–é¢„è§ˆå›¾
            let imageGenerator = AVAssetImageGenerator(asset: asset)
            imageGenerator.appliesPreferredTrackTransform = true
            let cgImage = try await imageGenerator.image(at: CMTime(seconds: duration.seconds / 2, preferredTimescale: 600)).image
            let previewImage = UIImage(cgImage: cgImage)
            
            return VideoPreviewInfo(
                duration: duration.seconds,
                resolution: naturalSize,
                frameRate: frameRate,
                hasAudio: hasAudio,
                previewImage: previewImage
            )
            
        } catch {
            log("è·å–è§†é¢‘é¢„è§ˆä¿¡æ¯å¤±è´¥: \(error)")
            return nil
        }
    }
}



/// è§†é¢‘ä¿¡æ¯ç»“æ„ä½“
struct VideoInfo {
    let duration: Double
    let naturalSize: CGSize
    let frameRate: Float
    let hasAudio: Bool
    let formatDescriptions: [CMFormatDescription]
    
    var description: String {
        return """
        è§†é¢‘ä¿¡æ¯:
        - æ—¶é•¿: \(String(format: "%.2f", duration)) ç§’
        - å°ºå¯¸: \(naturalSize.width) x \(naturalSize.height)
        - å¸§ç‡: \(frameRate) fps
        - éŸ³é¢‘: \(hasAudio ? "æœ‰" : "æ— ")
        - æ ¼å¼æè¿°: \(formatDescriptions.count) ä¸ª
        """
    }
}

/// è§†é¢‘é¢„è§ˆä¿¡æ¯ç»“æ„ä½“
struct VideoPreviewInfo {
    let duration: Double
    let resolution: CGSize
    let frameRate: Float
    let hasAudio: Bool
    let previewImage: UIImage
    
    var formattedDuration: String {
        let minutes = Int(duration) / 60
        let seconds = Int(duration) % 60
        return String(format: "%02d:%02d", minutes, seconds)
    }
    
    var formattedResolution: String {
        return "\(Int(resolution.width))Ã—\(Int(resolution.height))"
    }
    
    var description: String {
        return """
        æ—¶é•¿: \(formattedDuration)
        åˆ†è¾¨ç‡: \(formattedResolution)
        å¸§ç‡: \(String(format: "%.1f", frameRate)) fps
        éŸ³é¢‘: \(hasAudio ? "æœ‰" : "æ— ")
        """
    }
}

/// é¢„å¤„ç†é”™è¯¯ç±»å‹
enum PreprocessingError: LocalizedError {
    case fileNotFound
    case invalidFileAttributes
    case fileTooSmall
    case videoTooShort
    case noVideoTrack
    case exportSessionCreationFailed
    case exportFailed
    case imageProcessingFailed
    
    var errorDescription: String? {
        switch self {
        case .fileNotFound:
            return "è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨"
        case .invalidFileAttributes:
            return "æ— æ³•è¯»å–æ–‡ä»¶å±æ€§"
        case .fileTooSmall:
            return "è§†é¢‘æ–‡ä»¶å¤ªå°ï¼ˆ<0.1MBï¼‰"
        case .videoTooShort:
            return "è§†é¢‘æ—¶é•¿å¤ªçŸ­ï¼ˆ<1ç§’ï¼‰"
        case .noVideoTrack:
            return "è§†é¢‘æ–‡ä»¶æ²¡æœ‰è§†é¢‘è½¨é“"
        case .exportSessionCreationFailed:
            return "æ— æ³•åˆ›å»ºè§†é¢‘å¯¼å‡ºä¼šè¯"
        case .exportFailed:
            return "è§†é¢‘å¯¼å‡ºå¤±è´¥"
        case .imageProcessingFailed:
            return "å›¾åƒå¤„ç†å¤±è´¥"
        }
    }
}